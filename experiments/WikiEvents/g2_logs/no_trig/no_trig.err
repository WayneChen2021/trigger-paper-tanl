cp: -r not specified; omitting directory '../../../../original_scripts/MUC'
cp: -r not specified; omitting directory '../../../../original_scripts/WikiEvents'
cp: cannot stat '../../../../data//no_trig/train_event.json': No such file or directory
cp: cannot stat '../../../../data//no_trig/dev_event.json': No such file or directory
cp: cannot stat '../../../../data//no_trig/test_event.json': No such file or directory
/home/zc272/trigger-paper-tanl/experiments/WikiEvents/g2_environments/no_trig/no_trig/utils.py:15: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if episodes_string is not None and episodes_string is not '':
/home/zc272/.conda/envs/TANL2/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
Episode 0 (1 episodes total)
Output directory: experiments/wikievents_no_trig-t5-base-ep25-len512-b2-train/episode0
Using model t5-base
Traceback (most recent call last):
  File "/home/zc272/trigger-paper-tanl/experiments/WikiEvents/g2_environments/no_trig/no_trig/run.py", line 304, in <module>
    main()
  File "/home/zc272/trigger-paper-tanl/experiments/WikiEvents/g2_environments/no_trig/no_trig/run.py", line 228, in main
    dataset = load_dataset(
              ^^^^^^^^^^^^^
  File "/home/zc272/trigger-paper-tanl/experiments/WikiEvents/g2_environments/no_trig/no_trig/datasets.py", line 56, in load_dataset
    return DATASETS[dataset_name](
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zc272/trigger-paper-tanl/experiments/WikiEvents/g2_environments/no_trig/no_trig/base_dataset.py", line 95, in __init__
    self.load_schema()   # here the dataset can load information such as entity/relation types
    ^^^^^^^^^^^^^^^^^^
  File "/home/zc272/trigger-paper-tanl/experiments/WikiEvents/g2_environments/no_trig/no_trig/datasets.py", line 1881, in load_schema
    with open(types_file_name, 'r') as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'data/wikievents_no_trig/wikievents_no_trig_types.json'
